{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we use the output from the topic model and our immersion journal/manual to subset a training set of tweets about the Australian Bushfires. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing relevant packages\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm import tqdm #to create a progress bar\n",
    "\n",
    "#Load custom function for preprocessing the text\n",
    "\n",
    "#Machine learning packages\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Packages to create DFM\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#Packages for cross-validation and parameter tuning\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Packages for getting model performance metrics\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#Packages for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "#Word embeddings\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "#Gary King et. al key-words\n",
    "from keyword_algorithm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Gary Kings semi-automated keyword retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/final_df.csv\", index_col=0)\n",
    "#Subset period June 2019 – May 2020\n",
    "#data = data.loc[(data[\"created_at\"] >= \"2019-06-01\") & (data[\"created_at\"] <= \"2020-06-01\")]\n",
    "#data[\"id\"] = data.index\n",
    "data = data.dropna(subset = [\"lemmas\"]).reset_index(drop = True)\n",
    "data[\"index_col\"] = data.index\n",
    "#data.to_csv(\"data/query_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"data/wiki-news-300d-1M.vec\"\n",
    "fasttext = KeyedVectors.load_word2vec_format(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryBuilder:\n",
    "    \n",
    "    def __init__(self, emb_model):\n",
    "        \n",
    "        self.query = Keywords()\n",
    "        self.query.LoadDataset('data/query_df.csv', text_colname='lemmas', \n",
    "                               date_colname=\"created_at\", id_colname=\"index_col\")\n",
    "        self.we = emb_model\n",
    "        \n",
    "    def get_query(self, keywords):\n",
    "            \n",
    "            keepers = set()\n",
    "            \n",
    "            for keyword in keywords[\"accepted_keys\"]:\n",
    "                inp = input(f\"Should {keyword} go in ORs, ANDs\")\n",
    "                if inp == \"ORs\":\n",
    "                    keepers.add(keyword)\n",
    "                elif inp == \"ANDs\":\n",
    "                    for keyword2 in keywords[\"accepted_keys\"]:\n",
    "                        if keyword2 != keyword:\n",
    "                            inp2 = input(f\"keep ({keyword} AND {keyword2}), yes or no?\")\n",
    "                            if inp2 == \"yes\":\n",
    "                                keepers.add((f\"(?=.*{keyword})(?=.*{keyword2})\"))\n",
    "            \n",
    "                    for nokey in keywords[\"nontarget_keys\"]:\n",
    "                        inp3 = input(f\"keep ({keyword} AND NOT {nokey}), yes or no?\")\n",
    "                        if inp3 == \"yes\":\n",
    "                            keepers.add((f\"(^(?!.*{nokey})(?=.*{keyword})\"))\n",
    "            return keepers\n",
    "    \n",
    "    def get_keywords(self, its = 2, top_n = 10, refkeys = [], tarkeys = []):\n",
    "        \n",
    "        \n",
    "        accepted_keywords = []\n",
    "        rejected_keywords = []\n",
    "        nontarget_keywords = []\n",
    "        \n",
    "        #Begin loop for mining search set\n",
    "        for it in range(its):\n",
    "            print(\"-\"*66)\n",
    "            print(f\"STARTING ITERATION: {it}! INITIAL REFERENCE KEYS: {refkeys}\")\n",
    "            print(\"-\"*66)\n",
    "            \n",
    "            #Build reference set of tweets\n",
    "            self.query.ReferenceSet(any_words=refkeys, date_start=\"2019-06-01\", date_end=\"2020-05-30\")\n",
    "            if it > 0:\n",
    "                #fit model on searchset and find target\n",
    "                self.query.SearchSet(any_words= accepted_keywords, date_start=\"2019-06-01\", date_end=\"2020-05-30\")\n",
    "            else:\n",
    "                self.query.SearchSet(any_words = tarkeys, date_start=\"2019-06-01\", date_end=\"2020-05-30\")\n",
    "            \n",
    "            self.query.ProcessData(stem = False, keep_twitter_symbols=False,\n",
    "                                   remove_wordlist=refkeys)\n",
    "            self.query.ReferenceKeywords()\n",
    "            self.query.ClassifyDocs(min_df=10, ref_trainprop=1, algorithms=['nbayes', 'logit'])\n",
    "            self.query.FindTargetSet()\n",
    "            self.query.FindKeywords()\n",
    "            #Extract target keywords from model\n",
    "            target_keywords = self.query.target_keywords[:top_n]\n",
    "            #Also get the reference set keywords\n",
    "            target_keywords += self.query.reference_keywords[:top_n]\n",
    "            for nonkey in self.query.nontarget_keywords[:100]:\n",
    "                if nonkey not in nontarget_keywords:\n",
    "                    nontarget_keywords.append(nonkey)\n",
    "            \n",
    "            for keyword in target_keywords:\n",
    "                if keyword in accepted_keywords or keyword in rejected_keywords:\n",
    "                    continue\n",
    "                else:\n",
    "                    inp = input(f\"Keep {keyword.upper()} yes or no?\")\n",
    "                    if inp == \"yes\":\n",
    "                        accepted_keywords.append(keyword)\n",
    "                \n",
    "                        #get similar keywords through most similar pretrained embeddings\n",
    "                        inp2 = input(f\"Look at {keyword.upper()}'s most similar word embeddings, yes or no?\")\n",
    "                        if inp2 == \"yes\":\n",
    "                            try:\n",
    "                                embeddings = [emb[0] for emb in self.we.most_similar(keyword)]\n",
    "                                for emb in embeddings:\n",
    "                                    if emb.lower() in accepted_keywords or emb.lower() in rejected_keywords:\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        inp3 = input(f\"Keep embedding {emb.upper()} yes or no?\")\n",
    "                                        if inp3 == \"yes\":\n",
    "                                            accepted_keywords.append(emb)\n",
    "                                        elif inp3 ==\"no\":\n",
    "                                            rejected_keywords.append(emb)\n",
    "                            except:\n",
    "                                print(f\"{keyword.upper()} embedding not present in Model!\")\n",
    "                                pass\n",
    "                        elif inp2 == \"no\":\n",
    "                            pass\n",
    "                    elif inp == \"no\":\n",
    "                        rejected_keywords.append(keyword)\n",
    "                        \n",
    "            #Add custom keyword(s)\n",
    "            inp4 = input(f\"Do you wish to add any further keywords? If yes, Type keyword: \")\n",
    "            if inp4:\n",
    "                if isinstance(inp4, list):\n",
    "                    [accepted_keywords.append(key) for key in inp4]\n",
    "                else:\n",
    "                     accepted_keywords.append(inp4)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            print(\"-\"*66)\n",
    "            print(\" \"*20, f\"CURRENT KEYWORDS AFTER ITTERATION {it}\")\n",
    "            print(\"-\"*66)\n",
    "            print(f\"ACCEPTED: \\n {accepted_keywords}\")\n",
    "            print(f\"REJECTED: \\n {rejected_keywords}\")\n",
    "            \n",
    "        \n",
    "        keywords = {\"accepted_keys\":accepted_keywords, \"rejected_keys\":rejected_keywords,\"nontarget_keys\":nontarget_keywords}\n",
    "        \n",
    "        return keywords\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword object initialized.\n",
      "Loaded corpus of size 148540 in 3.0 seconds.\n"
     ]
    }
   ],
   "source": [
    "query = QueryBuilder(fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "STARTING ITERATION: 0! INITIAL REFERENCE KEYS: ['#bushfire', '#bushfires', 'bushfire', 'bushfires']\n",
      "------------------------------------------------------------------\n",
      "Loaded reference set of size 1682 in 1.63 seconds.\n",
      "Loaded search set of size 1368 in 0.44 seconds.\n",
      "Time to process corpus: 0.38 seconds\n",
      "\n",
      "4159 reference set keywords found.\n",
      "\n",
      "Document Term Matrix: 3050 by 857 with 33018 nonzero elements\n",
      "\n",
      "Time to get document-term matrix: 0.05 seconds\n",
      "\n",
      "Ref training size: 1682; Search training size: 451; Training size: 2133; Test size: 1368\n",
      "\n",
      "Time for Naive Bayes: 0.0 seconds\n",
      "Time for Logit: 0.03 seconds\n",
      "479 documents in target set\n",
      "889 documents in non-target set\n",
      "260 target set keywords found\n",
      "178 non-target set keywords found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keep GOVERNMENT yes or no? aa\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-340-0c5b9d14b4eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"#bushfire\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"#bushfires\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bushfire\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bushfires\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"fire\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-338-610d5fdd74b6>\u001b[0m in \u001b[0;36mget_keywords\u001b[0;34m(self, its, top_n, refkeys, tarkeys)\u001b[0m\n\u001b[1;32m     68\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Keep {keyword.upper()} yes or no?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0minp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"yes\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                         \u001b[0maccepted_keywords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keep SUPPORT yes or no? aa\n"
     ]
    }
   ],
   "source": [
    "keywords = query.get_keywords(2, top_n=10, refkeys=[\"#bushfire\", \"#bushfires\", \"bushfire\", \"bushfires\"], tarkeys = [\"fire\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"|\".join(keywords[\"accepted_keys\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the key-words from Kings model to subset tweets. Next we use this subset to predict the party of the tweet and analyze the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlogitMargins:\n",
    "    \"\"\"\n",
    "    Calculates marginal effect of logit coefficients with bootstraped confidence interval.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        \n",
    "        #Define data\n",
    "        self.vect = CountVectorizer(max_features=10000, ngram_range=(1,2))\n",
    "        self.X = self.vect.fit_transform(X)\n",
    "        self.y = y\n",
    "        print(\"Fitting model and calculating margins...\")\n",
    "        self.margins, self.fitted_model = self.marginal_effect(self.X, self.y)\n",
    "\n",
    "    def bootstrap(self, alpha = 0.05, n_iter = 500):\n",
    "        \n",
    "        \n",
    "        statistics = []\n",
    "        n_size = int(self.X.shape[0] * 0.60)\n",
    "        print(f\"Observations in bootstrap sample {n_size}.\")\n",
    "        for i in tqdm(range(n_iter)):\n",
    "\n",
    "            idx = np.random.choice(np.arange(self.X.shape[0]), n_size, replace=True)\n",
    "            X_sample = self.X[idx]\n",
    "            y_sample = self.y[idx]\n",
    "            \n",
    "            margins = self.marginal_effect(X_sample, y_sample)[0]\n",
    "            statistics.append(margins)\n",
    "        \n",
    "        #Join the resulting dataframes\n",
    "        statistics = pd.concat(statistics)\n",
    "        print(f\"Boostraping Done. Calculating {alpha}-{1-alpha} confidence interval...\")\n",
    "        start = time.time()\n",
    "        statistics = statistics.groupby(\"word\").quantile([alpha, 1-alpha]).reset_index()\n",
    "        \n",
    "        #statistics = statistics.agg\n",
    "        print(\"Time to calculate: \", time.time() - start)\n",
    "\n",
    "        return statistics\n",
    "        \n",
    "\n",
    "    def fit_model(self, X, y):\n",
    "        \n",
    "        logit = LogisticRegression(random_state=42, penalty=\"none\", solver=\"saga\", \n",
    "                                   max_iter = 10000,  class_weight = \"balanced\").fit(X, y)\n",
    "\n",
    "        return logit\n",
    "        \n",
    "    def marginal_effect(self, X, y):\n",
    "        \n",
    "        \n",
    "        model = self.fit_model(X, y)\n",
    "        \n",
    "        # Get predictions and coefficients\n",
    "        preds = model.predict_proba(X) # Shape discplines * N posts i.e. (6* approx. 246000)\n",
    "        coefs = model.coef_ # Shape discplines * N word tokens i.e. (6*10000))\n",
    "\n",
    "        # Define the denominator to calculate predicted \n",
    "        # probability of post i, for each field\n",
    "\n",
    "        denominator = sum([np.exp(preds[:,label]) for label in range(len(model.classes_))])\n",
    "\n",
    "        # Calculate probability of tweet i beloning to party k\n",
    "        probas = [(np.exp(preds[:,label]) / denominator) for label in range(len(model.classes_))]\n",
    "\n",
    "        # initiate \n",
    "        MEs = []\n",
    "\n",
    "        for index, label_proba in tqdm(enumerate(probas)):\n",
    "\n",
    "            temp = []\n",
    "            for beta_k in coefs[index]:\n",
    "                p_sum = (label_proba* (1-label_proba)).sum()\n",
    "                me = round((1 / len(probas[0])) * beta_k * p_sum, 3)\n",
    "                temp.append(me)\n",
    "\n",
    "            MEs.append(temp)\n",
    "\n",
    "        X_tokens = self.vect.get_feature_names()\n",
    "        df_data = {label:MEs[i] for i, label in enumerate(model.classes_)}\n",
    "        df_data[\"word\"] = X_tokens #Add word tokens\n",
    "\n",
    "        me_df = pd.DataFrame(df_data)\n",
    "\n",
    "\n",
    "        return me_df, model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query = \"|\".join(keywords[\"accepted_keys\"])\n",
    "#Extract most predictive keywords from model\n",
    "lasso_data = data.loc[(data[\"lemmas\"].str.contains(\"bushfire|bushfires|#bushfire|#bushfires|disaster|kaoala|fire|flames|firemen\") == True) & \n",
    "                      (data[\"lemmas\"].str.contains(\"corona|covid\") == False) & \n",
    "                      (data[\"created_at\"] >= \"2019-06-01\") & \n",
    "                      (data[\"created_at\"] <= \"2020-06-01\")]\n",
    "\n",
    "#df_agg = lasso_data.groupby([\"created_at\", \"name\"]).agg({\"lemmas\":\" \".join, \"party\":\"first\"}).reset_index()\n",
    "df_agg = df_agg.loc[df_agg[\"party\"].isin([\"Australian Greens\",\"Australian Labor Party\", \"Liberal Party of Australia\"])].dropna().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_agg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9013f3275dae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_agg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lemmas\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_agg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"party\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mMlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMlogitMargins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_agg' is not defined"
     ]
    }
   ],
   "source": [
    "X, y = df_agg[\"lemmas\"], df_agg[\"party\"]\n",
    "Mlogit = MlogitMargins(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations in bootstrap sample 835.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00,  7.29it/s]\n",
      "3it [00:00,  7.98it/s]\n",
      "3it [00:00,  7.86it/s]\n",
      "3it [00:00,  7.06it/s]\n",
      "3it [00:00,  7.58it/s]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boostraping Done. Calculating 0.05-0.95 confidence interval...\n",
      "Time to calculate:  0.057392120361328125\n"
     ]
    }
   ],
   "source": [
    "bs_res = Mlogit.bootstrap(n_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>level_1</th>\n",
       "      <th>Australian Greens</th>\n",
       "      <th>Australian Labor Party</th>\n",
       "      <th>Liberal Party of Australia</th>\n",
       "      <th>bootstrap_iteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>climate</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.2848</td>\n",
       "      <td>-0.0674</td>\n",
       "      <td>-0.1646</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>coal</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.2744</td>\n",
       "      <td>-0.1222</td>\n",
       "      <td>-0.0906</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>case</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.2362</td>\n",
       "      <td>0.0536</td>\n",
       "      <td>-0.0148</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>especially</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.2332</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0638</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>climate</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2294</td>\n",
       "      <td>-0.1514</td>\n",
       "      <td>-0.1890</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16274</th>\n",
       "      <td>support</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.1814</td>\n",
       "      <td>-0.1076</td>\n",
       "      <td>0.1516</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2422</th>\n",
       "      <td>community</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.1896</td>\n",
       "      <td>-0.0596</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>auspol</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.1976</td>\n",
       "      <td>0.2162</td>\n",
       "      <td>-0.1290</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3324</th>\n",
       "      <td>disaster</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.2076</td>\n",
       "      <td>0.2968</td>\n",
       "      <td>-0.1494</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>bushfire</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.2470</td>\n",
       "      <td>0.2590</td>\n",
       "      <td>-0.1010</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  level_1  Australian Greens  Australian Labor Party  \\\n",
       "2235      climate     0.95             0.2848                 -0.0674   \n",
       "2299         coal     0.95             0.2744                 -0.1222   \n",
       "1963         case     0.95             0.2362                  0.0536   \n",
       "3881   especially     0.95             0.2332                  0.0198   \n",
       "2234      climate     0.05             0.2294                 -0.1514   \n",
       "...           ...      ...                ...                     ...   \n",
       "16274     support     0.05            -0.1814                 -0.1076   \n",
       "2422    community     0.05            -0.1896                 -0.0596   \n",
       "736        auspol     0.05            -0.1976                  0.2162   \n",
       "3324     disaster     0.05            -0.2076                  0.2968   \n",
       "1482     bushfire     0.05            -0.2470                  0.2590   \n",
       "\n",
       "       Liberal Party of Australia  bootstrap_iteration  \n",
       "2235                      -0.1646                  3.8  \n",
       "2299                      -0.0906                  3.8  \n",
       "1963                      -0.0148                  3.8  \n",
       "3881                       0.0638                  3.8  \n",
       "2234                      -0.1890                  0.2  \n",
       "...                           ...                  ...  \n",
       "16274                      0.1516                  0.2  \n",
       "2422                       0.1258                  0.2  \n",
       "736                       -0.1290                  0.2  \n",
       "3324                      -0.1494                  0.2  \n",
       "1482                      -0.1010                  0.2  \n",
       "\n",
       "[20000 rows x 6 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_res.sort_values(\"Australian Greens\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fdd379f7bb8e06f7ec29e5b7f14bfd985640a300b5a41de1996cc2754af32f7b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('pyenv': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}